{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ninth DNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitinranjansharma/EIP4-Week1/blob/master/Week2/Ninth_DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfLcqQ_zPh5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization, Activation\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import GlobalMaxPool2D\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHIGcMM_P5c0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVI8xyMSQHId",
        "colab_type": "code",
        "outputId": "f4730b7d-d5d9-4d78-a1c3-04f72ae1e87f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4e4bee1e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2uzxiPIQL4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshaping for convolutions\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9iixYuIQVrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awEXgS-NcviU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[:10]\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUJYgmbtczaO",
        "colab_type": "code",
        "outputId": "f8351daf-9a66-45b4-ddae-b0dcd1c243e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "Y_train[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4402SKN9c2f2",
        "colab_type": "code",
        "outputId": "c99d3908-bf04-421e-8086-cfe14e66f486",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#last code from 8th Code base\n",
        "'''\n",
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Convolution2D(20, 3, 3, activation='relu')) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu')) #22\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#11\n",
        "\n",
        "model.add(Convolution2D(20, 3, 3, activation='relu'))#9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(10, 4, 4))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom keras.layers import Activation\\nmodel = Sequential()\\n \\nmodel.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1))) #26\\nmodel.add(BatchNormalization())\\nmodel.add(Dropout(0.15))\\n\\nmodel.add(Convolution2D(20, 3, 3, activation='relu')) #24\\nmodel.add(BatchNormalization())\\nmodel.add(Dropout(0.15))\\n\\nmodel.add(Convolution2D(10, 1, 1, activation='relu')) #22\\n\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))#11\\n\\nmodel.add(Convolution2D(20, 3, 3, activation='relu'))#9\\nmodel.add(BatchNormalization())\\nmodel.add(Dropout(0.15))\\n\\n\\nmodel.add(Convolution2D(16, 3, 3, activation='relu'))#7\\nmodel.add(BatchNormalization())\\nmodel.add(Dropout(0.15))\\n\\n\\nmodel.add(Convolution2D(16, 3, 3, activation='relu'))#5\\nmodel.add(BatchNormalization())\\nmodel.add(Dropout(0.15))\\n\\n\\nmodel.add(Convolution2D(16, 3, 3, activation='relu'))#3\\nmodel.add(BatchNormalization())\\nmodel.add(Dropout(0.15))\\n\\n\\nmodel.add(Convolution2D(10, 4, 4))\\nmodel.add(BatchNormalization())\\nmodel.add(Dropout(0.15))\\n\\n\\nmodel.add(GlobalAveragePooling2D())\\nmodel.add(Activation('softmax'))\\n\\n\\nmodel.summary()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prHFgFi3ghGy",
        "colab_type": "code",
        "outputId": "376e4a9f-a406-4521-d76a-ae827069ee96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "model1 = Sequential()\n",
        "\n",
        "model1.add(Convolution2D(filters=10,kernel_size=(3,3),strides=(1,1),kernel_initializer='he_uniform',activation='relu',use_bias=False,input_shape=(28,28,1)))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1)) # 26,26,16\n",
        "\n",
        "model1.add(Convolution2D(filters=20,kernel_size=(3,3),activation='relu',use_bias=False,kernel_initializer='he_uniform'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1)) # 24*24*32\n",
        "\n",
        "model1.add(Convolution2D(filters=20,kernel_size=(3,3),activation='relu',use_bias=False,kernel_initializer='he_uniform'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1)) # 24*24*32\n",
        "\n",
        "\n",
        "model1.add(Convolution2D(filters=10,kernel_size=(1,1),activation='relu',use_bias=False,kernel_initializer='he_uniform')) # 24*24*10\n",
        "model1.add(MaxPooling2D(pool_size=(2,2))) # 12*12*10\n",
        "\n",
        "model1.add(Convolution2D(filters=10,kernel_size=(3,3),activation='relu',use_bias=False,kernel_initializer='he_uniform'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1)) # 10*10*10\n",
        "\n",
        "model1.add(Convolution2D(filters=20,kernel_size=(3,3),activation='relu',use_bias=False,kernel_initializer='he_uniform')) \n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1)) # 8*8*20\n",
        "\n",
        "model1.add(Convolution2D(filters=20,kernel_size=(3,3),activation='relu',use_bias=False,kernel_initializer='he_uniform')) \n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1)) # 6*6*20\n",
        "\n",
        "#model1.add(Convolution2D(filters=16,kernel_size=(1,1),activation='relu',use_bias=False,kernel_initializer='he_uniform')) # 6*6*10\n",
        "#model1.add(MaxPooling2D(pool_size=(2,2))) # 4*4*10\n",
        "\n",
        "model1.add(Convolution2D(filters=10,kernel_size=(1,1),activation='relu',use_bias=False,kernel_initializer='he_uniform')) # 1*1*10\n",
        "model1.add(BatchNormalization())\n",
        "#model1.add(Dropout(0.1))\n",
        "\n",
        "model1.add(GlobalAveragePooling2D())\n",
        "\n",
        "#model1.add(Flatten())\n",
        "model1.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model1.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_186 (Conv2D)          (None, 26, 26, 10)        90        \n",
            "_________________________________________________________________\n",
            "batch_normalization_158 (Bat (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_132 (Dropout)        (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_187 (Conv2D)          (None, 24, 24, 20)        1800      \n",
            "_________________________________________________________________\n",
            "batch_normalization_159 (Bat (None, 24, 24, 20)        80        \n",
            "_________________________________________________________________\n",
            "dropout_133 (Dropout)        (None, 24, 24, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_188 (Conv2D)          (None, 22, 22, 20)        3600      \n",
            "_________________________________________________________________\n",
            "batch_normalization_160 (Bat (None, 22, 22, 20)        80        \n",
            "_________________________________________________________________\n",
            "dropout_134 (Dropout)        (None, 22, 22, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_189 (Conv2D)          (None, 22, 22, 10)        200       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_190 (Conv2D)          (None, 9, 9, 10)          900       \n",
            "_________________________________________________________________\n",
            "batch_normalization_161 (Bat (None, 9, 9, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_135 (Dropout)        (None, 9, 9, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_191 (Conv2D)          (None, 7, 7, 20)          1800      \n",
            "_________________________________________________________________\n",
            "batch_normalization_162 (Bat (None, 7, 7, 20)          80        \n",
            "_________________________________________________________________\n",
            "dropout_136 (Dropout)        (None, 7, 7, 20)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_192 (Conv2D)          (None, 5, 5, 20)          3600      \n",
            "_________________________________________________________________\n",
            "batch_normalization_163 (Bat (None, 5, 5, 20)          80        \n",
            "_________________________________________________________________\n",
            "dropout_137 (Dropout)        (None, 5, 5, 20)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_193 (Conv2D)          (None, 5, 5, 10)          200       \n",
            "_________________________________________________________________\n",
            "batch_normalization_164 (Bat (None, 5, 5, 10)          40        \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_27  (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 12,630\n",
            "Trainable params: 12,410\n",
            "Non-trainable params: 220\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXvx1P8FoPTr",
        "colab_type": "code",
        "outputId": "8deca9f2-113e-48d0-ca0a-a37941999add",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model1 = Sequential()\n",
        "\n",
        "model1.add(Convolution2D(filters=10,kernel_size=(3,3),strides=(1,1),kernel_initializer='he_uniform',activation='relu',use_bias=False,input_shape=(28,28,1)))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1)) # 26,26,16\n",
        "\n",
        "model1.add(Convolution2D(filters=10,kernel_size=(3,3),activation='relu',use_bias=False,kernel_initializer='he_uniform'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1)) # 24*24*32\n",
        "\n",
        "model1.add(Convolution2D(filters=16,kernel_size=(3,3),activation='relu',use_bias=False,kernel_initializer='he_uniform'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1)) # 24*24*32\n",
        "\n",
        "model1.add(Convolution2D(filters=20,kernel_size=(3,3),activation='relu',use_bias=False,kernel_initializer='he_uniform'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1)) # 24*24*32\n",
        "\n",
        "model1.add(Convolution2D(filters=10,kernel_size=(1,1),activation='relu',use_bias=False,kernel_initializer='he_uniform')) # 24*24*10\n",
        "model1.add(MaxPooling2D(pool_size=(2,2))) # 12*12*10\n",
        "\n",
        "model1.add(Convolution2D(filters=10,kernel_size=(3,3),activation='relu',use_bias=False,kernel_initializer='he_uniform'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1)) # 10*10*10\n",
        "\n",
        "model1.add(Convolution2D(filters=12,kernel_size=(3,3),activation='relu',use_bias=False,kernel_initializer='he_uniform')) \n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1)) # 8*8*20\n",
        "\n",
        "model1.add(Convolution2D(filters=16,kernel_size=(3,3),activation='relu',use_bias=False,kernel_initializer='he_uniform')) \n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1)) # 8*8*20\n",
        "\n",
        "model1.add(Convolution2D(filters=20,kernel_size=(3,3),activation='relu',use_bias=False,kernel_initializer='he_uniform')) \n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1)) # 6*6*20\n",
        "\n",
        "#model1.add(Convolution2D(filters=16,kernel_size=(1,1),activation='relu',use_bias=False,kernel_initializer='he_uniform')) # 6*6*10\n",
        "#model1.add(MaxPooling2D(pool_size=(2,2))) # 4*4*10\n",
        "\n",
        "model1.add(Convolution2D(filters=10,kernel_size=(1,1),activation='relu',use_bias=False,kernel_initializer='he_uniform')) # 1*1*10\n",
        "model1.add(BatchNormalization())\n",
        "#model1.add(Dropout(0.1))\n",
        "\n",
        "model1.add(GlobalAveragePooling2D())\n",
        "\n",
        "#model1.add(Flatten())\n",
        "model1.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model1.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_258 (Conv2D)          (None, 26, 26, 10)        90        \n",
            "_________________________________________________________________\n",
            "batch_normalization_222 (Bat (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_188 (Dropout)        (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_259 (Conv2D)          (None, 24, 24, 10)        900       \n",
            "_________________________________________________________________\n",
            "batch_normalization_223 (Bat (None, 24, 24, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_189 (Dropout)        (None, 24, 24, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_260 (Conv2D)          (None, 22, 22, 16)        1440      \n",
            "_________________________________________________________________\n",
            "batch_normalization_224 (Bat (None, 22, 22, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_190 (Dropout)        (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_261 (Conv2D)          (None, 20, 20, 20)        2880      \n",
            "_________________________________________________________________\n",
            "batch_normalization_225 (Bat (None, 20, 20, 20)        80        \n",
            "_________________________________________________________________\n",
            "dropout_191 (Dropout)        (None, 20, 20, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_262 (Conv2D)          (None, 20, 20, 10)        200       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 10, 10, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_263 (Conv2D)          (None, 8, 8, 10)          900       \n",
            "_________________________________________________________________\n",
            "batch_normalization_226 (Bat (None, 8, 8, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_192 (Dropout)        (None, 8, 8, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_264 (Conv2D)          (None, 6, 6, 12)          1080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_227 (Bat (None, 6, 6, 12)          48        \n",
            "_________________________________________________________________\n",
            "dropout_193 (Dropout)        (None, 6, 6, 12)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_265 (Conv2D)          (None, 4, 4, 16)          1728      \n",
            "_________________________________________________________________\n",
            "batch_normalization_228 (Bat (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_194 (Dropout)        (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_266 (Conv2D)          (None, 2, 2, 20)          2880      \n",
            "_________________________________________________________________\n",
            "batch_normalization_229 (Bat (None, 2, 2, 20)          80        \n",
            "_________________________________________________________________\n",
            "dropout_195 (Dropout)        (None, 2, 2, 20)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_267 (Conv2D)          (None, 2, 2, 10)          200       \n",
            "_________________________________________________________________\n",
            "batch_normalization_230 (Bat (None, 2, 2, 10)          40        \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_35  (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 12,794\n",
            "Trainable params: 12,546\n",
            "Non-trainable params: 248\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z29x_7w6H5f",
        "colab_type": "code",
        "outputId": "031070b9-fbf5-4797-e083-cd7bc5602422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        }
      },
      "source": [
        "# final updated model\n",
        "model1 = Sequential()\n",
        "\n",
        "model1.add(Convolution2D(filters=16,kernel_size=(3,3),strides=(1,1),kernel_initializer='he_uniform',activation='relu',use_bias=False,input_shape=(28,28,1)))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1)) # 26,26,16\n",
        "\n",
        "model1.add(Convolution2D(filters=16,kernel_size=(3,3),activation='relu',use_bias=False,kernel_initializer='he_uniform'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1)) # 24*24*32\n",
        "\n",
        "\n",
        "model1.add(Convolution2D(filters=10,kernel_size=(1,1),activation='relu',use_bias=False,kernel_initializer='he_uniform')) # 24*24*10\n",
        "model1.add(MaxPooling2D(pool_size=(2,2))) # 12*12*10\n",
        "\n",
        "model1.add(Convolution2D(filters=10,kernel_size=(3,3),activation='relu',use_bias=False,kernel_initializer='he_uniform'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1)) # 10*10*10\n",
        "\n",
        "model1.add(Convolution2D(filters=16,kernel_size=(3,3),activation='relu',use_bias=False,kernel_initializer='he_uniform')) \n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1)) # 8*8*20\n",
        "\n",
        "model1.add(Convolution2D(filters=16,kernel_size=(3,3),activation='relu',use_bias=False,kernel_initializer='he_uniform')) \n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1)) # 8*8*20\n",
        "\n",
        "model1.add(Convolution2D(filters=16,kernel_size=(3,3),activation='relu',use_bias=False,kernel_initializer='he_uniform')) \n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.1)) # 6*6*20\n",
        "\n",
        "\n",
        "model1.add(Convolution2D(filters=10,kernel_size=(4,4),activation='relu',use_bias=False,kernel_initializer='he_uniform')) # 1*1*10\n",
        "model1.add(BatchNormalization())\n",
        "#model1.add(Dropout(0.1))\n",
        "\n",
        "model1.add(GlobalAveragePooling2D())\n",
        "\n",
        "#model1.add(Flatten())\n",
        "model1.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model1.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_276 (Conv2D)          (None, 26, 26, 16)        144       \n",
            "_________________________________________________________________\n",
            "batch_normalization_238 (Bat (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_202 (Dropout)        (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_277 (Conv2D)          (None, 24, 24, 16)        2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_239 (Bat (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_203 (Dropout)        (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_278 (Conv2D)          (None, 24, 24, 10)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_39 (MaxPooling (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_279 (Conv2D)          (None, 10, 10, 10)        900       \n",
            "_________________________________________________________________\n",
            "batch_normalization_240 (Bat (None, 10, 10, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_204 (Dropout)        (None, 10, 10, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_280 (Conv2D)          (None, 8, 8, 16)          1440      \n",
            "_________________________________________________________________\n",
            "batch_normalization_241 (Bat (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_205 (Dropout)        (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_281 (Conv2D)          (None, 6, 6, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_242 (Bat (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_206 (Dropout)        (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_282 (Conv2D)          (None, 4, 4, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_243 (Bat (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_207 (Dropout)        (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_283 (Conv2D)          (None, 1, 1, 10)          2560      \n",
            "_________________________________________________________________\n",
            "batch_normalization_244 (Bat (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_37  (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_37 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 12,516\n",
            "Trainable params: 12,316\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eqrNa_5c-d8",
        "colab_type": "code",
        "outputId": "339c1a66-3b00-41b0-d539-d3b5f275ca67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 20)\n",
        "\n",
        "model1.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model1.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 24s 398us/step - loss: 0.0457 - acc: 0.9862 - val_loss: 0.0378 - val_acc: 0.9894\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.002274450341167551.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0374 - acc: 0.9888 - val_loss: 0.0340 - val_acc: 0.9910\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018315018317.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0347 - acc: 0.9895 - val_loss: 0.0301 - val_acc: 0.9904\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586101175269.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0323 - acc: 0.9905 - val_loss: 0.0287 - val_acc: 0.9926\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.001318101933216169.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0284 - acc: 0.9916 - val_loss: 0.0256 - val_acc: 0.9937\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560693641618498.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0266 - acc: 0.9925 - val_loss: 0.0214 - val_acc: 0.9939\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.001029512697323267.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0247 - acc: 0.9926 - val_loss: 0.0241 - val_acc: 0.9933\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307145066501.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0243 - acc: 0.9927 - val_loss: 0.0220 - val_acc: 0.9944\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445945945945946.\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0227 - acc: 0.9933 - val_loss: 0.0224 - val_acc: 0.9939\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935417204857.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0235 - acc: 0.9930 - val_loss: 0.0229 - val_acc: 0.9942\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159904534606206.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0223 - acc: 0.9934 - val_loss: 0.0233 - val_acc: 0.9942\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0006653359946773121.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0214 - acc: 0.9938 - val_loss: 0.0221 - val_acc: 0.9943\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753106876554.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0219 - acc: 0.9938 - val_loss: 0.0236 - val_acc: 0.9940\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638041577617.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0202 - acc: 0.9941 - val_loss: 0.0216 - val_acc: 0.9942\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474204171241.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0192 - acc: 0.9945 - val_loss: 0.0208 - val_acc: 0.9947\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825410544512.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0204 - acc: 0.9942 - val_loss: 0.0217 - val_acc: 0.9944\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491480996068152.\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0193 - acc: 0.9943 - val_loss: 0.0228 - val_acc: 0.9944\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670714619336759.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0191 - acc: 0.9946 - val_loss: 0.0222 - val_acc: 0.9943\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718184514981.\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0182 - acc: 0.9946 - val_loss: 0.0209 - val_acc: 0.9942\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.00042486899872539303.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0188 - acc: 0.9942 - val_loss: 0.0209 - val_acc: 0.9945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4e4aec63c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qB_eElaeCv4",
        "colab_type": "code",
        "outputId": "57823995-139f-44b4-be85-4888b405c53d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "score = model1.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.04700799718648195, 0.9885]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2CDVzH8eoSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}